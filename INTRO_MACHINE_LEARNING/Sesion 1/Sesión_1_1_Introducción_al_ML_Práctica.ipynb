{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 1: GTSRB dataset\n",
        "---\n",
        "\n",
        "En este ejemplos vamos a cargar el conjunto de datos llamado [GTSRB (German Traffic Sign Recognition Benchmark)](https://benchmark.ini.rub.de/gtsrb_news.html) con casi 52.000 imágenes de señales de tráfico clasificadas en 43 categorías.\n",
        "\n",
        "Para esto vamos a ir siguiendo una serie de pasos, empezando por descargar el dataset a utilizar..."
      ],
      "metadata": {
        "id": "PsAbF3qjn53-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dlsi.ua.es/~jgallego/ml/gtsrb.npz\n",
        "\n",
        "print('\\n¡Base de datos cargada!')\n"
      ],
      "metadata": {
        "id": "m5H9j1Nhn3xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "Una vez descargada la base de datos de Internet escribimos el código para cargarla en memoria:\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "kpafURnBETXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np      # Importamos las librerías necesarias\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "def show_random_images(x, y):\n",
        "  n = 15\n",
        "  index = np.random.randint(len(x), size=n)\n",
        "  plt.figure(figsize=(n*1.5, 1.5))\n",
        "  for i in np.arange(n):\n",
        "      ax = plt.subplot(1,n,i+1)\n",
        "      ax.set_title('{} ({})'.format(y[index[i]],index[i]))\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "      plt.imshow(x[index[i]], cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Cargamos los datos y mostramos algunas imágenes de ejemplo\n",
        "data = np.load('gtsrb.npz')\n",
        "\n",
        "x = data['x']\n",
        "y = data['y']\n",
        "\n",
        "show_random_images(x, y)\n",
        "\n"
      ],
      "metadata": {
        "id": "qsa1PEWJoG4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "A continuación imprimimos la forma de los datos, el número de etiquetas y el número de muestras por clase que incluye este dataset:\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "IduIXDBfEeUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nForma de los datos:', x.shape)\n",
        "print('\\nForma de las etiquetas:', y.shape)\n",
        "\n",
        "NUM_LABELS = len(np.unique(y))\n",
        "\n",
        "print('\\nNúmero de clases:', NUM_LABELS)\n",
        "\n",
        "print('\\nNúmero de muestras por clase:')\n",
        "print(np.unique(y, return_counts=True)[1])\n"
      ],
      "metadata": {
        "id": "34KasH10oOYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos las particiones usando Numpy:"
      ],
      "metadata": {
        "id": "K5Ip-b4hoqHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = len(x)\n",
        "\n",
        "train_size = int(num_samples * .8)    # Asignamos el 80% a train\n",
        "\n",
        "x_train = x[:train_size]\n",
        "y_train = y[:train_size]\n",
        "x_test = x[train_size:]\n",
        "y_test = y[train_size:]\n",
        "\n",
        "print('X_train shape:', x_train.shape)\n",
        "print('Y_train shape:', y_train.shape)\n",
        "\n",
        "print('X_test shape:', x_test.shape)\n",
        "print('Y_test shape:', y_test.shape)\n",
        "\n",
        "print('\\nDistribución de los datos en train:')\n",
        "print(' - Número de clases:', len(np.unique(y_train)))\n",
        "print(' - Número de muestras por clase:', np.unique(y_train, return_counts=True)[1])\n",
        "\n",
        "print('\\nDistribución de los datos en test:')\n",
        "print(' - Número de clases:', len(np.unique(y_train)))\n",
        "print(' - Número de muestras por clase:', np.unique(y_test, return_counts=True)[1])"
      ],
      "metadata": {
        "id": "dYQo5fFxorz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "Para solucionar el problema anterior con las particiones vamos a usar la función [`train_test_split` de la librería Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
        "\n",
        "Los parámetros de este método son los siguientes (se indican los valores por defecto):\n",
        "\n",
        "* `*arrays`: Podemos crear particiones de uno o más arrays (por eso pone *) de forma simultánea (importante).\n",
        "\n",
        "* `test_size=None`: Tamaño de test (entre 0 y 1).\n",
        "\n",
        "* `train_size=None`: Tamaño de train (entre 0 y 1). Lo normal es indicar solo uno de estos dos parámetros.\n",
        "\n",
        "* `random_state=None`: Semilla (valor entero) de inicialización para el barajado. Importante para la reproducibilidad.\n",
        "\n",
        "* `shuffle=True`: Activa el barajado de las muestras. Importante: el barajado se realiza en todos los arrays por igual.\n",
        "\n",
        "* `stratify=None`: [Estratifica](https://en.wikipedia.org/wiki/Stratified_sampling) el número de muestras de cada clase en las particiones. Es decir, el número de muestras asignadas a cada partición (train/test) será proporcional al número de elementos de la clase.\n",
        "\n",
        "<br>\n",
        "\n",
        "A continuación usamos esta función para solucionar el problema previo con las particiones:\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "k35zrEjdoUmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
        "                                                    train_size=0.8,\n",
        "                                                    random_state=1,\n",
        "                                                    shuffle=True,\n",
        "                                                    stratify=y)\n",
        "\n",
        "# Mostramos la forma de los datos\n",
        "\n",
        "print('X_train shape:', x_train.shape)\n",
        "print('Y_train shape:', y_train.shape)\n",
        "\n",
        "print('X_test shape:', x_test.shape)\n",
        "print('Y_test shape:', y_test.shape)\n",
        "\n",
        "\n",
        "# Mostramos la distribución de los datos\n",
        "\n",
        "print('\\nDistribución de los datos en train:')\n",
        "print(' - Número de clases:', len(np.unique(y_train)))\n",
        "print(' - Número de muestras por clase:', np.unique(y_train, return_counts=True)[1])\n",
        "\n",
        "print('\\nDistribución de los datos en test:')\n",
        "print(' - Número de clases:', len(np.unique(y_train)))\n",
        "print(' - Número de muestras por clase:', np.unique(y_test, return_counts=True)[1])"
      ],
      "metadata": {
        "id": "0KKnSst1oT4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo 2 - Dataset de vinos\n",
        "---\n",
        "\n",
        "Vamos a probar con otro tipo de dataset en el que se clasifican la procedencia de tres tipos de vinos en función de una serie de características:\n",
        "\n",
        "- Alcohol\n",
        "- Ácido málico\n",
        "- Ceniza\n",
        "- Alcalinidad de la ceniza\n",
        "- Magnesio\n",
        "- Fenoles totales\n",
        "- Flavonoides\n",
        "- Fenoles no flavonoides\n",
        "- Proantocianinas\n",
        "- Intensidad de color\n",
        "- Tono\n",
        "- OD280/OD315 de vinos diluidos\n",
        "- Prolina\n",
        "\n",
        "<br/>\n",
        "\n",
        "Esta base de datos está disponible en los [ejemplos de Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html), así que usamos directamente la función proporcionada para la carga:\n",
        "\n",
        "<br/>\n"
      ],
      "metadata": {
        "id": "MtrLvxkDDCeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine_dataset = load_wine()\n",
        "\n",
        "print(wine_dataset.DESCR)\n"
      ],
      "metadata": {
        "id": "w3_bk1OmEADA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "\n",
        "A continuación usamos la librería Pandas para mostrar algunos ejemplos de este dataset:\n",
        "\n",
        "<br/>"
      ],
      "metadata": {
        "id": "K5-4DaVnJ8Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "wine = pd.DataFrame(wine_dataset.data, columns=wine_dataset.feature_names)\n",
        "\n",
        "wine['Target'] = wine_dataset.target    # Añadimos la columna objetivo\n",
        "\n",
        "print(wine)"
      ],
      "metadata": {
        "id": "SCHVii-4I0YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "Aprovechamos Pandas para mostrar datos estadísticos sobre las características de este dataset:\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "Xz0yZ0APM085"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Llamamos a la utilidad de descripción de pandas\n",
        "\n",
        "wine.describe()"
      ],
      "metadata": {
        "id": "AW9y_1k2MqTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "\n",
        "Por último vamos a guardar las características y las etiquetas en arrays de Numpy para crear las particiones como hemos visto previamente:\n",
        "\n",
        "<br/>"
      ],
      "metadata": {
        "id": "nqDCuZdHKbDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array( wine_dataset.data )\n",
        "y = np.array( wine_dataset.target )\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
        "                                                    train_size=0.8,\n",
        "                                                    random_state=1,\n",
        "                                                    shuffle=True,\n",
        "                                                    stratify=y)\n",
        "\n",
        "# Mostramos la forma de los datos\n",
        "\n",
        "print('X_train shape:', x_train.shape)\n",
        "print('Y_train shape:', y_train.shape)\n",
        "\n",
        "print('X_test shape:', x_test.shape)\n",
        "print('Y_test shape:', y_test.shape)\n",
        "\n",
        "\n",
        "# Mostramos la distribución de los datos\n",
        "\n",
        "print('\\nDistribución de los datos en train:')\n",
        "print(' - Número de clases:', len(np.unique(y_train)))\n",
        "print(' - Número de muestras por clase:', np.unique(y_train, return_counts=True)[1])\n",
        "\n",
        "print('\\nDistribución de los datos en test:')\n",
        "print(' - Número de clases:', len(np.unique(y_train)))\n",
        "print(' - Número de muestras por clase:', np.unique(y_test, return_counts=True)[1])"
      ],
      "metadata": {
        "id": "9ZK7Ry7oKk6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}