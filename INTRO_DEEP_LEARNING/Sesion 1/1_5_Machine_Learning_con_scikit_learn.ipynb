{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTtpYjlARmXc"
      },
      "source": [
        "<center><img src=\"https://www.dlsi.ua.es/~juanra/UA/curso_verano_DL/images/sklearn-logo.png\" height=\"100\"></center>\n",
        "\n",
        "# 1.5 Machine Learning con scikit-learn\n",
        "\n",
        "Profesor: Juan Ramón Rico (<juanramonrico@ua.es>)\n",
        "\n",
        "## Resumen\n",
        "---\n",
        " **scikit-learn**: es el principal paquete de aprendizaje automático (Machine Learning) de propósito general en `Python`. Tiene gran cantidad de algoritmos y módulos para el pre-procesamiento, validación cruzada y ajuste de hiper-parámetros de modelos, clasificación/regresión, etc.\n",
        "- Documentación <http://scikit-learn.org/stable/documentation.html>\n",
        "- Tutorial de inicio rápido <http://elitedatascience.com/python-machine-learning-tutorial-scikit-learn>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-m1B9GOyTaK"
      },
      "source": [
        "# Paquete scikit-learn\n",
        "\n",
        "- Funciones simples y eficientes para minería de datos y análisis de datos en general.\n",
        "- Contiene gran variedad de algoritmos de Machine Learning. Además, tiene funciones de preprocesado, filtrado y transformación de datos.\n",
        "- Construida sobre NumPy, SciPy, y Matplotlib\n",
        "- Código abierto, se permite su uso comercial - Licencia BSD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEe5xOeH1RRQ"
      },
      "source": [
        "# Conceptos básicos sobre Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJw_N40R1Uic"
      },
      "source": [
        "## Tipos de algoritmos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcyseY-og4bg"
      },
      "source": [
        "Un esquema resumen de los tipos de algoritmos de `Machine Learning` sería el siguiente\n",
        "\n",
        "<!-- source https://docs.google.com/drawings/d/1yGLRoDCTwZy7GGSl8rqui92SZzmKSxIAw46jAihKE-U/edit -->\n",
        "<center>\n",
        "<img src=\"https://docs.google.com/drawings/d/e/2PACX-1vQLsr-OobW1vG7ZBEDWqCNc3CzpNaDEdhFiXfWaKZ6nWDv0y7gLml4KHbSwa8D7_ZGeYFG6502PmC_E/pub?w=771&amp;h=314\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L1jzV5k4l3u"
      },
      "source": [
        "### Aprendizaje supervisado\n",
        "\n",
        "Típicamente son los algoritmos de clasificación o regresión donde se necesita conocer los datos de las entradas y su resultado (objetivo o salida) donde el sistema de aprendizaje trata de predecir los resultados de entradas que nunca ha visto.\n",
        "\n",
        "<center><img src=\"https://www.dlsi.ua.es/~juanra/UA/curso_verano_DL/images/supervised_learning.png\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsfIBUox8sGW"
      },
      "source": [
        "### Aprendizaje no supervisado\n",
        "\n",
        "El aprendizaje de estos algoritmos solo se aplica a los datos de entrada, ya que se desconocen sus resultados. Son típicos los algoritmos de agrupación (clustering) para conocer los grupos que se forman con los datos de entrada.\n",
        "\n",
        "<center><img src=\"https://www.dlsi.ua.es/~juanra/UA/curso_verano_DL/images/unsupervised_learning.png\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOJ2d4zL8yHl"
      },
      "source": [
        "### Aprendizaje por refuerzo\n",
        "\n",
        "El algoritmo aprende observando el mundo que le rodea. Tiene mayor dificultad que los dos tipos anteriores y necesita más datos. La información de entrada es la retroalimentación que obtiene del mundo exterior como respuesta a sus acciones. Por lo tanto, el sistema aprende a base de ensayo-error. Se aplica entornos simulados típicamente vídeo juegos para recoger tanta cantidad de datos como se necesiten, o en robótica para que el sistema interactue con el entorno.\n",
        "\n",
        "<center><img src=\"https://www.dlsi.ua.es/~juanra/UA/curso_verano_DL/images/reinforcement_learning.png\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNsK29Fotyx5"
      },
      "source": [
        "## ¿Cómo evaluar un modelo de clasificación o regresión?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqmxtqqqt8Ob"
      },
      "source": [
        "* Existen varias técnicas para evaluar un modelo antes de usarlo en producción, o bien para comparlo con otro y saber que grado de acierto tiene.\n",
        "\n",
        "* La técnica más usada actualmente se llama de [**validación cruzada**](https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada) (cros-validation en inglés).\n",
        "\n",
        "* La idea básica es dividir los datos disponibles en **dos grupos**: un grupo se usaría para entrenar el modelo y el otro grupo para comprobar el grado de acierto (tasa de aciertos en clasificación, o medir el error cometido en regresión).\n",
        "\n",
        "* Este proceso se repite varias veces (normalmente 10) y de forma ordenada.\n",
        "\n",
        "* Finalmente se calcula su media aritmética que nos servirá para conocer el grado de predicción del modelo.\n",
        "\n",
        "<center><img src=\"https://www.dlsi.ua.es/~juanra/UA/curso_verano_DL/images/10_fold_cv.png\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlL7dkvzz5D8"
      },
      "source": [
        "En todos los modelos que se aprenden hay que tener presente **dos conceptos clave**.\n",
        "\n",
        "La capacidad de un modelo de reconocer o pronosticar un valor en base a nuevos datos que no se han usado en la fase de entrenamiento (**generalización**), o bien, en base datos que sí se han usado en el entrenamiento (**memorización**).\n",
        "\n",
        "<center><img src=\"https://www.dlsi.ua.es/~juanra/UA/curso_verano_DL/images/balanza_mg.png\" height=\"200\"></center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94z71L4LUVzN"
      },
      "source": [
        "# Pruebas sobre clasificación y regresión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dniV3w1-Vs_i"
      },
      "source": [
        "## Importar paquetes que vamos a usar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3KyA2kMVy7Z"
      },
      "source": [
        "import numpy as np   # Manejo de vectores\n",
        "import pandas as pd  # Manipulación de tablas de datos\n",
        "import sklearn       # Gran colección de algorimos de Machine Learning juntos a otros de filtrado, preprocesado y cálculo de resultados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWnDJ8nKU08Y"
      },
      "source": [
        "## Copiar conjuntos de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_pRbzZTRgWL"
      },
      "source": [
        "# Hay que copiar los archivos de ejemplo\n",
        "!wget https://www.dlsi.ua.es/~juanra/UA/curso_verano_DL/data/basic_data.zip\n",
        "!unzip basic_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgEvs470VkeL"
      },
      "source": [
        "## Cargar iris.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjuDrxUa2iLa"
      },
      "source": [
        "En 1935 Edgar Anderson hizo un estudio en el que recolectó las diferencias en las medidas (ancho y largo de los pétalos y sépalos) de tres variedades de flores tipo iris que están estrechamente relacionadas. Este [ejemplo sencillo de 150 muestras de flores tipo iris](https://en.wikipedia.org/wiki/Iris_flower_data_set) se incluye en la mayoría de libros y programas relacionados con análisis o predicción de datos.\n",
        "\n",
        "<center><img src=\"https://www.dlsi.ua.es/~juanra/UA/curso_verano_DL/images/iris-ml.png\"></center>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAZPXghcSe6D"
      },
      "source": [
        "data = pd.read_csv('./basic_data/iris.csv')\n",
        "display(data.head())\n",
        "display(data.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9W72DwhWsk7"
      },
      "source": [
        "# Convirtiendo los tipos de 64 a 32 bits\n",
        "pairs = {'int64':'int32', 'float64':'float32'}\n",
        "for i in data.columns:\n",
        "  data[i]= data[i].astype(pairs.get(str(data[i].dtype), data[i].dtype))\n",
        "\n",
        "data['class'] = data['class'].astype('category')\n",
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWeHmmM8bWbG"
      },
      "source": [
        "## Visualización de los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I93OWPitXqFS"
      },
      "source": [
        "# Diagrama de cajas general\n",
        "data.boxplot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xoLU5i_bceH"
      },
      "source": [
        "# Diagrama de cajas por clases\n",
        "data.groupby('class').boxplot(layout=(1,3),figsize=(20,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PAW4Vk7c68b"
      },
      "source": [
        "## Clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyXki78Htw4L"
      },
      "source": [
        "### Preparar datos para la clasificación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JsUofcRt4ua"
      },
      "source": [
        "X = data[['sepallength','sepalwidth','petallength','petalwidth']].values\n",
        "y = data['class'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynEpmhSQrMNw"
      },
      "source": [
        "### Calcular los aciertos de un solo clasificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzj3z7d5rQWz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)\n",
        "model = KNeighborsClassifier(3)\n",
        "model.fit(X_train, y_train)\n",
        "score = model.score(X_test, y_test)\n",
        "print(f'aciertos: {score:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcmSofw0w7ou"
      },
      "source": [
        "# Nueva muestra\n",
        "x_new = [[6.7, 3.2, 6.1, 2.3]]\n",
        "\n",
        "print(f'Decisión: {model.predict(x_new)}')\n",
        "print(f'Posibilidades: {data[\"class\"].cat.categories}')\n",
        "print(f'Probabilidades: {model.predict_proba(x_new)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Nota**: la función `train_test_split()` se usa a modo de de ejemplo. Para la evaluación de un modelo predictivo lo habitual es usar funciones de validación cruzada en la que un modelo es evaluado varias veces para estimar su comportamiento."
      ],
      "metadata": {
        "id": "gQObuHyOzWnd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfF1cG3FnOPa"
      },
      "source": [
        "### Calcular los aciertos de  varios clasificadores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psQCOCOkc910"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
        "         \"Decision Tree\", \"Random Forest\", \"MLP\", \"AdaBoost\",\n",
        "         \"Naive Bayes\", \"Logistic Regression\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\"),\n",
        "    SVC(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    MLPClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    LogisticRegression()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7RDumUPnWfv"
      },
      "source": [
        "### Resultados con validación cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elRDBPVpmdba"
      },
      "source": [
        "%%capture --no-stdout\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=123)\n",
        "# iterate over classifiers\n",
        "for name, model in zip(names, classifiers):\n",
        "  results = cross_val_score(model, X, y, cv=cv)\n",
        "  print(f'{name:20s} media: {results.mean():.02f} resultados: {np.round(results,2)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6W0V11yoIx8"
      },
      "source": [
        "## Regresión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk3AwRl-oPUE"
      },
      "source": [
        "### Preparar los datos para calcular la regresión\n",
        "\n",
        "Para realizar una predicción basada en valores vamos a usar el siguiente conjunto de datos que relaciona la calidad del aire y la mortalidad.\n",
        "\n",
        "La ficha de este conjunto de datos es:\n",
        "- Data from OpenML (<https://www.openml.org/search?type=data&sort=runs&id=542&status=active>)\n",
        "- Description: This is the pollution data so loved by writers of papers on ridge regression.\n",
        "- Source: McDonald, G.C. and Schwing, R.C. (1973) 'Instabilities of regression estimates relating air pollution to mortality', Technometrics, vol.15, 463-482.\n",
        "- Variables in order:\n",
        "    - PREC   Average annual precipitation in inches\n",
        "    - JANT   Average January temperature in degrees F\n",
        "    - JULT   Same for July\n",
        "    - OVR65  % of 1960 SMSA population aged 65 or older\n",
        "    - POPN   Average household size\n",
        "    - EDUC   Median school years completed by those over 22\n",
        "    - HOUS   % of housing units which are sound & with all facilities\n",
        "    - DENS   Population per sq. mile in urbanized areas, 1960\n",
        "    - NONW   % non-white population in urbanized areas, 1960\n",
        "    - WWDRK  % employed in white collar occupations\n",
        "    - POOR   % of families with income < $3000\n",
        "    - HC     Relative hydrocarbon pollution potential\n",
        "    - NOX    Same for nitric oxides\n",
        "    - SO@    Same for sulphur dioxide\n",
        "    - HUMID  Annual average % relative humidity at 1pm\n",
        "    - MORT   Total age-adjusted mortality rate per 100,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuecuTjHoIMF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('./basic_data/pollution.csv')\n",
        "display(data.head())\n",
        "\n",
        "data_X, data_y = data.iloc[:,:-1].values, data.iloc[:,-1].values\n",
        "\n",
        "# Cantidad de datos\n",
        "print('data shape: ',data_X.shape, data_y.shape)\n",
        "plt.hist(data_y)\n",
        "plt.show()\n",
        "\n",
        "# Dividir entre entrenamiento y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.1, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Nota**: la función `train_test_split()` se usa a modo de de ejemplo. Para la evaluación de un modelo predictivo lo habitual es usar funciones de validación cruzada en la que un modelo es evaluado varias veces para estimar su comportamiento."
      ],
      "metadata": {
        "id": "1r8_eKWC0BVY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5sbBUutrNv0"
      },
      "source": [
        "### Aplicar un algoritmo de regresión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCb_NtNFrNv4"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model = KNeighborsRegressor(3)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "score = sklearn.metrics.mean_absolute_error(y_test, y_pred)\n",
        "print(f'mean absolute error (mae): {score:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M_aqGgu2GCn"
      },
      "source": [
        "# Suponemos que queremos predecir una nueva muestra\n",
        "\n",
        "print(data.columns)\n",
        "x_new = np.array([X_test[-1]]) # Última muestra de test\n",
        "print(f'Características: {x_new[0]}')\n",
        "print(f'Predicción: {model.predict(x_new)[0]}')\n",
        "print(f'Valor real: {y_test[-1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odoMGOmatIlU"
      },
      "source": [
        "### Aplicar varios algoritmos de regresión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RerNPLl4tIlY"
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regressors = [\n",
        "  (\"Nearest Neighbors\", KNeighborsRegressor(3)),\n",
        "  (\"Linear Regression\", LinearRegression()),\n",
        "  (\"Decision Tree\",     DecisionTreeRegressor()),\n",
        "  (\"Random Forest\",     RandomForestRegressor()),\n",
        "  (\"Neural Net\",        MLPRegressor()),\n",
        "  (\"AdaBoost\",          AdaBoostRegressor()),\n",
        "  (\"Gaussina Proc.\",    GaussianProcessRegressor()),\n",
        "  (\"SVM Linear\",        SVR(kernel='linear')),\n",
        "  (\"SVM Radial\",        SVR(kernel='rbf')),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKnyIjamv4Nv"
      },
      "source": [
        "### Resultados con validación cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GMvZG3Xv4Ny"
      },
      "source": [
        "%%capture --no-stdout\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# iterate over classifiers\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=123)\n",
        "estimators = [ ('standardize', StandardScaler()), () ]\n",
        "for name, reg in regressors:\n",
        "  estimators[1]=(name, reg)\n",
        "  pipeline = Pipeline(estimators)\n",
        "\n",
        "  results = -cross_val_score(pipeline, data_X, data_y, scoring='neg_mean_absolute_error', cv=cv)\n",
        "  print(f'{name:20s} media: {results.mean():.02f} resultados: {np.round(results,2)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxG9bRlY39YL"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5ESNcU23_e-"
      },
      "source": [
        "* Aprendizaje **supervisado** y **no supervisado**.\n",
        "\n",
        "* Evaluación de modelos con la técnica de **validación cruzada**.\n",
        "\n",
        "* Planteamiento de problemas como una función **mapeado $ f(X) = y $** (supervisado), teniendo un conjunto de características $X$ queremos obtener la clase o el valor $y$.\n",
        "\n",
        "* Ejemplos sencillos de **clasificación** y **regresión**, además de como aplicar varios algoritmos sobre el mismo conjunto de datos.\n",
        "\n",
        "* **scikit-learn** paquete de referencia en Python para usar ténicas de Machine Learning. Contiene los principales algoritmos de clasificación, regresión así como otros complementarios de evaluación de modelos, filtrado, escalado, deteccción de atípicos, etc."
      ]
    }
  ]
}