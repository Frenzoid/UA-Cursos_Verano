{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDRnWCqlB0HM"
      },
      "source": [
        "# 2.1. Redes neuronales\n",
        "\n",
        "* Las Redes Neuronales fueron originalmente una **simulación abstracta de los sistemas nerviosos biológicos**.\n",
        "\n",
        "* El primer modelo de red neuronal fue propuesto en [1943 por McCulloch y Pitts](https://link.springer.com/article/10.1007%2FBF02478259) en términos de un modelo computacional de actividad nerviosa. Posteriormente, [Frank Rosenblatt en 1958](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.3398&rep=rep1&type=pdf) propuso el primer modelo de neurona o perceptrón. Y finalmente en [1986 Rumelhart, Hinton y Williams](https://web.stanford.edu/class/psych209a/ReadingsByDate/02_06/PDPVolIChapter8.pdf) propusieron el perceptrón multicapa.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Deep Learning Timeline](http://www.dlsi.ua.es/~jgallego/deepraltamira/deep_learning_timeline_1.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "* Las redes neuronales están formadas por un conjunto de unidades llamadas **neuronas** o nodos **conectados unos con otros** imitando el comportamiento observado en los axones de las neuronas en los cerebros biológicos.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "![red neuronal](http://www.dlsi.ua.es/~jgallego/deepraltamira/neural_network.jpg)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "* La redes neuronales siempre se organizan en capas, con:\n",
        "\n",
        " * Una capa de entrada.\n",
        "\n",
        " * Una o más capas oculas.\n",
        "\n",
        " * Una capa de salida.\n",
        "\n",
        "* Cada neurona está conectada con todas las neuronas de la capa anterior.\n",
        "\n",
        "* Los enlaces entre las neuronas pueden modificar el estado de activación de las neuronas con las que se conecta.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcamoN5f6OpG"
      },
      "source": [
        "## Neurona o perceptron\n",
        "\n",
        "Cada neurona de la red se estructura de la siguiente forma:\n",
        "\n",
        "<br>\n",
        "\n",
        "![neurona](http://www.dlsi.ua.es/~jgallego/deepraltamira/neurona1.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "Es decir:\n",
        "\n",
        "* Recibe $x_n$ entradas.\n",
        "\n",
        "* Pondera estas entradas por unos pesos $w$.\n",
        "\n",
        "* Suma el resultado de esta ponderación.\n",
        "\n",
        "* Le añade un umbral o bias $b$.\n",
        "\n",
        "* Y pasa este resultado por una función $f$ de activación.\n",
        "\n",
        "<br>\n",
        "\n",
        "La expresión matemática de una neurona sería:\n",
        "\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "y = f \\Big( \\sum w_n x_n + b \\Big)\n",
        "\\end{equation}\n",
        "\n",
        "<br>\n",
        "\n",
        "Por lo que (si no tenemos en cuenta la función $f$ de activación) en realidad está aplicando una **función lineal** como la siguiente:\n",
        "\n",
        "<br>\n",
        "\n",
        "![clasificación lineal](http://www.dlsi.ua.es/~jgallego/deepraltamira/linear_classification.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "Al añadir la función de activación y combinar el resultado de las distintas neuronas capa tras capa lo que obtenemos es un **clasificador no lineal** con el que podemos hacer discriminaciones como la siguiente:\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "![non linear classification](http://www.dlsi.ua.es/~jgallego/deepraltamira/non_linear_classification.png)\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSeFcy2j6SAW"
      },
      "source": [
        "## Función de activación\n",
        "\n",
        "* La salida de cada neurona se transforma aplicando una función de activación.\n",
        "\n",
        "* De esta forma podemos modificar la salida de la neurona, aplicar **funciones no lineales**, restringir la salida a un rango dado (entre 0 y 1, o entre -1 y 1) o a valores discretos (0 ó 1).\n",
        "\n",
        "* En general es mejor utilizar funciones no lineales que devuelvan valores contínuos, ya que esto nos permitirá aprender clasificadores más complejos.\n",
        "\n",
        "* También dependiendo de la función utilizada será más fácil o costoso el aprendizaje de los pesos.\n",
        "\n",
        "* Esta función tiene que ser **derivable** para poder calcular la pendiente en un punto dado. De esta forma, durante el entrenamiento, podremos saber cómo ajustar los pesos para reducir el error.\n",
        "\n",
        "* Las funciones de activación más utilizadas son la función **Softmax**, la **Sigmoidal** y la **Rectified Linear Unit (ReLU)**, pero hay muchas más:\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "![activation functions](http://www.dlsi.ua.es/~jgallego/deepraltamira/activation_functions.jpg)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "### Salida de la red en problemas de clasificación categórica\n",
        "\n",
        "* Podemos utilizar la función sigmoidea como salida en problemas de clasificación binaria.\n",
        "\n",
        "* Cuando tenemos más de dos clases se puede añadir una neurona de salida con función sigmoidea para cada clase.\n",
        "\n",
        "* Aunque en estos casos se recomienda utilizar la función de activación **Softmax** para la salida de la red.\n",
        "\n",
        "* La función **Softmax** asigna probabilidades en el rango $[0, 1]$ a cada clase.\n",
        "\n",
        "* Las probabilidades sumarán 1. Esta restricción adicional permite que el entrenamiento converja más rápido.\n",
        "\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\sigma : \\mathbb{R} ^{K} \\to [0, 1]^K\n",
        "\\end{equation}\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX840KbL6Y5L"
      },
      "source": [
        "## Entrenamiendo de la red\n",
        "\n",
        "* Inicialmente los pesos de las neuronas ($w$ y $b$), y de la red en general, se inicializan con valores aleatorios.\n",
        "\n",
        "* El proceso de entrenamiento consiste en encontrar la combinación de pesos que mejor se ajuste a una muestra de entrenamiento dada.\n",
        "\n",
        "<br>\n",
        "\n",
        "![clasificación lineal](http://www.dlsi.ua.es/~jgallego/deepraltamira/linear_classification_animation.gif)\n",
        "\n",
        "<br>\n",
        "\n",
        "* Este proceso trata de encontrar un mínimo en la superficie de error formada a partir de los parámetros de la red y la muestra de entrenamiento.\n",
        "\n",
        "* Este proceso suele ser muy complejo dado que la superficie normalmente será N-dimensional y contendrá muchos valles, además, en cada momento solo sabemos el **error cometido en ese punto**, con la configuración de parámetros actual.\n",
        "\n",
        "<br>\n",
        "\n",
        "![backpropagation surface](http://www.dlsi.ua.es/~jgallego/deepraltamira/backpropagation_surface.jpg)\n",
        "\n",
        "<br>\n",
        "\n",
        "* Este proceso de entrenamiento se realiza utilizando el método de \"**propagación hacia atrás de errores**\" o \"**retropropagación**\" o, del inglés, ***backpropagation***.\n",
        "\n",
        "* Este método funciona en dos fases:\n",
        "\n",
        " 1. **Paso forward o hacia adelante:** se suministran las muestras de entrenamiento a la red, se obtiene la predicción y se compara esta salida con la salida deseada. Con esto se puede calcular el error (usando una función de error o ***loss***) para cada una de las salidas.\n",
        "\n",
        " 2. **Paso backward o hacia atrás:** El error calculado se propaga hacia atrás desde la capa de salida. Cada neurona recibirá la fracción de error cometido por la misma.\n",
        "   \n",
        "   * Este proceso lo realizaremos utilizando el método de optimización de **descenso por gradiente**, el cual se basa en calcular la pendiente en el punto actual y actualizar los pesos **un poco** (que dependerá del parámetro de aprendizaje *learning rate*), moviéndonos en la dirección opuesta al gradiente.\n",
        "\n",
        "<br>\n",
        "\n",
        "![backpropagation method](http://www.dlsi.ua.es/~jgallego/deepraltamira/backpropagation_method.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "* Además del descenso por gradicente (*gradient descent*) hay otros muchos algoritmos optimizadores que podemos utilizar: *Stochastic gradient descent (SGD), RMSprop, Adagrad, Adadelta, Adam,*...\n",
        "\n",
        "<br>\n",
        "\n",
        "![Optimizadores](http://www.dlsi.ua.es/~jgallego/deepraltamira/backpropagation_optimizers.gif)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "* Una vez finaliza el proceso de entrenamiento ya se puede usar la red con los pesos aprendidos para hacer predicciones o clasificaciones. En esta etapa solo será necesario realizar el paso hacia adelante.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9-PjZBtAqv1"
      },
      "source": [
        "### Ejemplo sencillo con una neurona\n",
        "\n",
        "\n",
        "A continuación vamos a ver un ejemplo sencillo de como implementar y entrenar manualmente una red neuronal que recibirá como entrada datos 2D y utilizará una única neurona para clasificar estos datos en dos clases.\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlg7282z8N2A"
      },
      "source": [
        "\"\"\"\n",
        "En primer lugar importamos la librerías necesarias y generamos datos de\n",
        "entrenamiento aleatorios.\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)  # Fijamos la semilla\n",
        "\n",
        "# -------------------------------\n",
        "def plot(x, y, pred=None):\n",
        "  x0 = x[y == 0]\n",
        "  x1 = x[y == 1]\n",
        "  plt.plot(x0[:,0], x0[:,1], 'go')\n",
        "  plt.plot(x1[:,0], x1[:,1], 'bo')\n",
        "\n",
        "  if pred is not None:\n",
        "    e = x[y != pred]  # Nos quedamos con los errores de predicción\n",
        "    plt.plot(e[:,0], e[:,1], 'ro', ms=10)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "print('Datos aleatorios generados para el entrenamiento:')\n",
        "\n",
        "x_train = np.random.random((500,2))\n",
        "y_train = np.array([(0.5 * x_train[:,0] + 0.2 > x_train[:,1])]).astype(int).T\n",
        "\n",
        "plot(x_train, y_train.T[0])\n",
        "\n",
        "print('Forma de los datos generados:')\n",
        "print('X:', x_train.shape, 'Y:', y_train.shape)\n",
        "print('\\nMostramos los valores de los 5 primeros elementos:')\n",
        "print('X:', x_train[:5])\n",
        "print('Y:', y_train[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26rCbPKrxdpS"
      },
      "source": [
        "\"\"\"\n",
        "A continuación entrenamos la red neuronal\n",
        "\"\"\"\n",
        "\n",
        "# -------------------------------\n",
        "# Función sigmoidea\n",
        "def nonlin(x, deriv=False):\n",
        "    if(deriv==True):\n",
        "        return x*(1-x)\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "# Inicializamos los pesos de forma aleatoria con media 0\n",
        "weights0 = 2 * np.random.random((2,1)) - 1\n",
        "bias0 = np.array([0.0])   # Inicializamos el bias\n",
        "\n",
        "\n",
        "epocas = 1000\n",
        "print('Entrenamos durante {} epocas'.format(epocas))\n",
        "\n",
        "for iter in range(epocas):\n",
        "    # Paso Forward\n",
        "    prediccion = nonlin(np.dot(x_train, weights0) + bias0)\n",
        "\n",
        "    # Calculamos el error cometido\n",
        "    error = y_train - prediccion\n",
        "    if iter % 100 == 0:\n",
        "      print(' - Epoca {} - Error {:0.4f}'.format(iter, np.mean(np.fabs(error)) ))\n",
        "\n",
        "    # Multiplicamos el error cometido por la pendiente de la función en ese\n",
        "    # punto, así obtenemos el incremento que tenemos que aplicar sobre los pesos\n",
        "    delta = error * nonlin(prediccion, True)\n",
        "\n",
        "    # Actualizamos los pesos\n",
        "    weights0 += np.dot(x_train.T, delta)\n",
        "    bias0 += np.sum(delta)\n",
        "\n",
        "print('Error final del entrenamiento: {:0.4f}'.format( np.mean(np.fabs(error)) ))\n",
        "print('Aciertos con los datos de entrenamiento: {:0.2f}%'.format( accuracy_score(y_train, prediccion > .5) * 100 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDdcwmHxx0n1"
      },
      "source": [
        "\"\"\"\n",
        "Y por último evaluamos la red con los pesos aprendidos con un nuevo conjunto\n",
        "de datos\n",
        "\"\"\"\n",
        "\n",
        "print('Generamos nuevos datos aleatorios para la evaluación:')\n",
        "\n",
        "x_test = np.random.random((100,2))\n",
        "y_test = np.array([(0.5 * x_test[:,0] + 0.2 > x_test[:,1])]).astype(int).T\n",
        "\n",
        "\n",
        "# Realizamos el paso Forward por la red\n",
        "prediccion = nonlin(np.dot(x_test, weights0) + bias0)\n",
        "\n",
        "\n",
        "# Calculamos el resultado obtenido y lo mostramos\n",
        "prediccion = np.array(prediccion > .5).astype(int)\n",
        "\n",
        "plot(x_test, y_test.T[0], prediccion.T[0])\n",
        "\n",
        "print(\"Aciertos con los datos de evaluación: {:0.2f}%\".format( accuracy_score(y_test, prediccion)*100 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYGbjYhQAB21"
      },
      "source": [
        "<br>\n",
        "\n",
        "* Pero para crear una red neuronal más compleja, con más capas y neuronas por capa, la implementación manual se complica.\n",
        "\n",
        "<br>\n",
        "\n",
        "![red neuronal](http://www.dlsi.ua.es/~jgallego/deepraltamira/neural_network.jpg)\n",
        "\n",
        "<br>\n",
        "\n",
        "* En las redes neuronales con más capas se han de combinar el resultado de muchas neuronas y funciones de activación.\n",
        "\n",
        "* Además, para entrenar la red y ajustar los pesos de neuronas intermedias se han de realizar cálculos mucho más complejos, ya que el resultado de cada neurona (y por lo tanto el error cometido) depende del resto de neuronas.\n",
        "\n",
        "* Para facilitar la implementación de redes neuronales más complejas podemos utilizar librerías que nos ayuden en esta labor.\n",
        "\n",
        "* **[tf.Keras](https://keras.io/)** es una librería de alto nivel para el desarrollo de redes neuronales con las siguientes características:\n",
        "\n",
        " * Está escrita en Python.\n",
        " * Está enfocada en permitir la experimentación rápida, poder pasar de la idea al resultado con el menor retraso posible.\n",
        " * Incorpora los últimos avances: tipos de redes convolucionales, recurrentes, etc.\n",
        " * Puede funcionar con GPU y CPU.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8160yyX7yHK0"
      },
      "source": [
        "# 2.1.1. Redes neuronales con tf.Keras\n",
        "\n",
        "* En tf.Keras disponemos de las clases **`Sequential`** y **`Dense`** para crear una red neuronal tipo secuencial formada por capas de neuronas.\n",
        "\n",
        "* La clase [`Sequential`](https://keras.io/models/sequential/) nos permite crear un modelo de red \"secuencial\" y además nos proporciona los siguientes métodos:\n",
        "\n",
        " * `compile`: compila la red para prepararla para el entrenamiento y evaluación. Además nos permite indicar el [optimizador](https://keras.io/optimizers/) (SGD, Adam, etc.) y función de pérdida (función utilizada para calcular el error cometido, también llamada *loss*) a utilizar.\n",
        "\n",
        " * `fit`: Inicia el entrenamiento de la red. En este método tenemos que indicar los datos de entrenamiento, el número de épocas y tamaño del batch a utilizar.\n",
        "\n",
        " * `evaluate`: Evalua la red usando la función de pérdida y métricas indicadas al compilar.\n",
        "\n",
        " * `predict`: Devuelve la predicción de la red para nuevas muestras.\n",
        "\n",
        "* La clase [`Dense`](https://keras.io/api/layers/core_layers/dense/) nos permite añadir capas de neuronas a la red. Para esto solo tenemos que indicar como parámetro el número de neuronas de la capa y la función de activación a utilizar en cada neurona. Por ejemplo:\n",
        "\n",
        " * `Dense(10, activation='sigmoid')` --> Añade una capa a la red neuronal con 10 neuronas y activación sigmoidea.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "&#10158; El código que tendríamos que escribir en tf.Keras para clasificar los mismos datos del ejemplo anterior sería:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9faMtYiSymwL"
      },
      "source": [
        "# Cargamos las dependencias\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)  # Fijamos la semilla de TF\n",
        "\n",
        "\n",
        "# Definimos la red tipo secuencial\n",
        "model = Sequential()\n",
        "\n",
        "# Añadimos una capa con 1 neurona.\n",
        "# En esta misma capa indicamos que la entrada de la red será de dimensión 2.\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=2))\n",
        "\n",
        "\n",
        "# Mostramos un resumen de la red\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "# La compilamos\n",
        "model.compile(optimizer=SGD(learning_rate=.05), loss='mae', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Iniciamos el entrenamiento\n",
        "model.fit(x_train, y_train, epochs=300, batch_size=64, verbose=2)\n",
        "\n",
        "\n",
        "# Utilizamos el modelo aprendido para predecir el resultado del conjunto de test\n",
        "prediccion = model.predict( x_test )\n",
        "\n",
        "\n",
        "print(\"Datos de evaluación:\")\n",
        "prediccion = np.array(prediccion > .5).astype(int)\n",
        "plot(x_test, y_test.T[0], prediccion.T[0])\n",
        "print(\"Aciertos en la evaluación: {:0.2f}%\".format( accuracy_score(y_test, prediccion)*100 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv8wA662UyJo"
      },
      "source": [
        "<br>\n",
        "\n",
        "* Mediante las clases `Sequential` y `Dense` podemos definir el MLP como nosotros queramos.\n",
        "\n",
        "* Podemos añadir más capas, por ejemplo crear una red con 3 capas ocultas de 100 neuronas, 50 neuronas de entrada y 10 de salida:\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=50))\n",
        "model.add(Dense(100))\n",
        "model.add(Dense(100))\n",
        "model.add(Dense(10))\n",
        "```\n",
        "\n",
        "* Podemos utilizar diferentes funciones de activación. Una de las funciones de activación más utilizadas actualmente es **ReLU**:\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=50))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeQCWxnLX_sd"
      },
      "source": [
        "## Activación de la capa de salida\n",
        "\n",
        "* La función de activación a utilizar en la capa de salida dependerá del problema que pretendamos resolver.\n",
        "\n",
        " * Si pretendemos predecir un valor continuo --> **activación lineal** (sin activación)\n",
        "\n",
        " * Si vamos a clasificar múltiples categorías --> **softmax**\n",
        "\n",
        " * Para dos categorías podemos utilizar softmax o sigmoidea.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "![Overfitting example](http://www.dlsi.ua.es/~jgallego/deepraltamira/fig_example_categorical.png)\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QizH9iW3a99w"
      },
      "source": [
        "### Clasificación categórica\n",
        "\n",
        "* En los problemas de clasificación categórica tendremos una serie de etiquetas a clasificar, por ejemplo: \"perro\", \"gato\", \"oso\" y \"pez\".\n",
        "\n",
        "* Estas etiquetas o clases las podemos representar (o codificar) mediante valores numéricos: 0=\"perro\", 1=\"gato\", 2=\"oso\" y 3=\"pez\".\n",
        "\n",
        "* El problema es que esto representa una serie continua de valores que la red podría aprender, además la red también tendería a devolver etiquetas con valores más altos.\n",
        "\n",
        "* Para evitar estos problemas se ha de transformar las etiquetas al formato \"[One hot](https://en.wikipedia.org/wiki/One-hot)\".\n",
        "\n",
        "* En este formato, cada etiqueta se representa mediante un vector binario, donde todas las posiciones valen 0 excepto la de la clase a representar, que tendrá valor 1. Por ejemplo, para las clases del ejemplo con animales anterior tendríamos:\n",
        "  * \"0:perro\"&nbsp; --> [1, 0, 0, 0]\n",
        "  * \"1:gato\" &nbsp; --> [0, 1, 0, 0]\n",
        "  * \"2:oso\" &nbsp;&nbsp; --> [0, 0, 1, 0]\n",
        "  * \"3:pez\" &nbsp;&nbsp; --> [0, 0, 0, 1]\n",
        "\n",
        "* Para realizar esta transformación utilizaremos la función [`keras.utils.to_categorical`](https://keras.io/api/utils/python_utils/#to_categorical-function).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neRtlvXqhZMS"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Por ejemplo, tenemos el siguiente vector de etiquetas:\n",
        "\n",
        "Y = [1, 3, 0, 2, 1, 0, 3]\n",
        "\n",
        "numero_total_clases = 4    # Del 0 al 3\n",
        "\n",
        "print('Vector de etiquetas antes de la conversión:')\n",
        "print(Y)\n",
        "\n",
        "Y = to_categorical(Y, numero_total_clases)\n",
        "\n",
        "print('\\nVector one-hot:')\n",
        "print(Y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZqF4LhCf1BW"
      },
      "source": [
        "## Entrenamiento y evaluación\n",
        "\n",
        "* Para el entrenamiento y la evaluación de una red neuronal (y de cualquier algoritmo de aprendizaje en general) se recomienda dividir los datos a clasificar en dos conjuntos:\n",
        "\n",
        " * Un **conjunto** para el **entrenamiento** con aproximadamente el 80% del total de los datos.\n",
        "\n",
        " * Y otro **conjunto** para la **evaluación o test** con los datos restantes.\n",
        "\n",
        "* De esta forma, una vez entrenado el modelo lo podemos validar con datos que no ha visto.  \n",
        "\n",
        "* El resultado obtenido con un conjunto de test separado nos permite evaluar si el modelo **ha aprendido a generalizar** y, por lo tanto, a clasificar nueva información.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Train and test split](http://www.dlsi.ua.es/~jgallego/deepraltamira/fig_train_test.png)\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e60gstrJlZM2"
      },
      "source": [
        "## Épocas y batch\n",
        "\n",
        "* Como ya hemos visto, durante el entrenamiento se van suministrando muestras a la red, se calcula el error cometido entre la predicción de la red y las etiquetas reales, y se ajustan los pesos para reducir este error utilizando el algoritmo \"backpropagation\".\n",
        "\n",
        "* Si este proceso lo realizamos muestra a muestra, una **época** de entrenamiento se refiere a cuando hemos suministrado todas las muestras de entrenamiento. Por lo tanto, realizar más épocas se refiere a volver a entrenar suministrando las mismas muestras una y otra vez.\n",
        "\n",
        "* Además, en vez de realizar este proceso muestra a muestra, lo podemos realizar por lotes, grupos, o **batchs**, es decir, suministrando un grupo de muestras a la red y ajustando el error de forma conjunta para ese grupo.\n",
        "\n",
        "* Este último método es el que utilizan la mayoría de optimizadores, como por ejemplo Stochastic Gradient Descent (SGD), RMSprop, Adagrad, Adadelta, Adam, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxqBfOapBE_i"
      },
      "source": [
        "## Overfitting\n",
        "\n",
        "* Se denomina \"*overfitting*\" al efecto producido al sobreentrenar (o sobreajustar) un algoritmo de aprendizaje a unos ciertos datos para los que se conoce el resultado deseado.\n",
        "\n",
        "* Cuando un sistema se sobreentrena el algoritmo puede quedar **ajustado a unas características muy específicas de los datos de entrenamiento** que no tienen relación causal con la función objetivo.\n",
        "\n",
        "* En este caso el algoritmo no generaliza.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "![Overfitting example](http://www.dlsi.ua.es/~jgallego/deepraltamira/overfitting_example.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "* Este problema es bastante frecuente al entrenar redes neuronales (en general).\n",
        "\n",
        "* El motivo suele ser:\n",
        "\n",
        " * Pocos datos de entrenamiento.\n",
        "\n",
        " * Uso de modelos de red no adecuados a la cantidad o variabilidad de los datos de entrenamiento.\n",
        "\n",
        "* Si representamos en una gráfica el error cometido por la red durante el entrenamiento para la muestra de aprendizaje (training) y la de validación (validation), un ejemplo típico de overfitting sería:\n",
        "\n",
        "<br>\n",
        "\n",
        "![Overfitting curve](http://www.dlsi.ua.es/~jgallego/deepraltamira/overfitting_curve1.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "* Tenemos diferentes soluciones para evitar este problema:\n",
        "\n",
        " * Detener el entrenamiento antes de que suceda (en la línea de puntos de la gráfica).\n",
        "\n",
        " * Si es demasiado pronto para detener el entrenamiento (porque el error todavía es alto) y tiene una **varianza alta** podríamos:\n",
        "\n",
        "   * Añadir más datos o datos más variados al training set.\n",
        "   * Aplicar aumentado de datos.\n",
        "   * Reducir la complejidad de la red neuronal.\n",
        "   * Usar técnicas para evitar el overfitting como **Dropout** o **Batch Normalization**.\n",
        "\n",
        "* En los casos en los que tengamos un **bias alto** deberemos aumentar el tamaño de la red o modificar su topología."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dkIdr2EusCA"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "* Esta operación consiste en desconectar aleatoriamente un porcentaje de las neuronas de la red en cada iteración del entrenamiento.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Dropout](http://www.dlsi.ua.es/~jgallego/deepraltamira/dropout.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "* En tf.Keras tenemos la clase [Dropout](https://keras.io/api/layers/regularization_layers/dropout/) que nos permite aplicar fácilmente esta técnica sobre las capas de la red.\n",
        "\n",
        "* Esta clase recibe como parámetro el porcentaje (entre 0 y 1) de las neuronas a desactivar en cada iteración.\n",
        "\n",
        "* Podemos añadir esta clase después de cada capa densa, por ejemplo:\n",
        "\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkpyrM-Lio8r"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**[&#10158;  Vamos a practicar &#10158; ](https://colab.research.google.com/drive/1bXjwrGJtQG09AUGKTudIXtOXPCALiMkf)**\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}